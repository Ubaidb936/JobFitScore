{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635b6956-4ecb-40f6-9622-cf4435b84365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import requests\n",
    "import sys\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "803923ac-3e60-4dfb-a741-cc1e861b8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569be603-5c95-488f-8032-afb61940ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "HF_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff08985-b1d4-4506-b9be-b3a56f68c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c99542-b5ca-42ee-be4b-f10c97d7e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "WARNING! repo_id is not default parameter.\n",
      "                    repo_id was transferred to model_kwargs.\n",
      "                    Please confirm that repo_id is what you intended.\n",
      "WARNING! task is not default parameter.\n",
      "                    task was transferred to model_kwargs.\n",
      "                    Please confirm that task is what you intended.\n",
      "WARNING! huggingfacehub_api_token is not default parameter.\n",
      "                    huggingfacehub_api_token was transferred to model_kwargs.\n",
      "                    Please confirm that huggingfacehub_api_token is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.chat_models import ChatHuggingFace\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id= model_id,\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token = HF_TOKEN,\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "    },\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3131ee8-a688-4488-98f2-a7a94ff72044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "QA_generation_prompt = \"\"\"\n",
    "Your task is to summarize in 1500 characters the experiences and skills from a given resume in a format that \n",
    "facilitates easy comparison with a job description.\n",
    "\n",
    "Provide your summary as follows:\n",
    "\n",
    "Output:::\n",
    "Summary: (your summary of the experience from the resume, structured for easy comparison with a job description)\n",
    "\n",
    "Now here is the resume.\n",
    "\n",
    "Resume: {resume}\\n\n",
    "Output:::\"\"\"\n",
    "\n",
    "QA_generation_prompt = ChatPromptTemplate.from_template(QA_generation_prompt)\n",
    "QA_generation_agent = QA_generation_prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "caa23d31-d298-482c-9c09-10ad86bf57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTextFromResume(file):\n",
    "    loader = PyPDFLoader(file)\n",
    "    pages = loader.load_and_split()\n",
    "    resume = \"\"\n",
    "    i = 0\n",
    "    for page in pages:\n",
    "        if i != 0:\n",
    "            resume += \"\\n\"\n",
    "        resume += page.page_content\n",
    "        i += 1\n",
    "    return resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2836f45e-7a0e-4147-84cd-a7b06367f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumeSummary(resume):\n",
    "    output = QA_generation_agent.invoke({\"resume\": resume}).content\n",
    "    try:\n",
    "        summary = output.split(\"Summary:\")[2].split(\"Answer: \")[0]\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return \"No summary of the resume....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "305ace83-4780-49c5-9024-fc8502f2fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7882\n",
      "Running on public URL: https://9c980c35486fbf82bc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9c980c35486fbf82bc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(file, jobDescription):\n",
    "    resume = loadTextFromResume(file)\n",
    "    summary = resumeSummary(resume) \n",
    "    return resume\n",
    "    \n",
    "    \n",
    "    \n",
    "           \n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload Resume pdf only\"),\n",
    "        gr.Textbox(label=\"Job Description\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"JobFitScore\"\n",
    ")\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf303f-86bc-48fc-ae32-76b1c8d2aebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
