{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635b6956-4ecb-40f6-9622-cf4435b84365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import requests\n",
    "import sys\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569be603-5c95-488f-8032-afb61940ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "HF_TOKEN = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "from huggingface_hub import login\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c99542-b5ca-42ee-be4b-f10c97d7e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "WARNING! repo_id is not default parameter.\n",
      "                    repo_id was transferred to model_kwargs.\n",
      "                    Please confirm that repo_id is what you intended.\n",
      "WARNING! task is not default parameter.\n",
      "                    task was transferred to model_kwargs.\n",
      "                    Please confirm that task is what you intended.\n",
      "WARNING! huggingfacehub_api_token is not default parameter.\n",
      "                    huggingfacehub_api_token was transferred to model_kwargs.\n",
      "                    Please confirm that huggingfacehub_api_token is what you intended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40776dcd74f4654952a575a4744e5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24924d0727ec4279942ec4f53fa5b81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9f13cfb8e64d10b8ece2937698d18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef277acdc2249b8b9cc73431c36cd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.chat_models import ChatHuggingFace\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id= \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token = HF_TOKEN,\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "    },\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3131ee8-a688-4488-98f2-a7a94ff72044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "resume_summary_generation_prompt = \"\"\"\n",
    "Your task is to summarize in 1500 characters the experiences and skills from a given resume in a format that \n",
    "facilitates easy comparison with a job description.\n",
    "\n",
    "Provide your summary as follows:\n",
    "\n",
    "Output:::\n",
    "Summary: (your summary of the experience from the resume, structured for easy comparison with a job description)\n",
    "\n",
    "Now here is the resume.\n",
    "\n",
    "Resume: {resume}\\n\n",
    "Output:::\"\"\"\n",
    "\n",
    "resume_summary_generation_prompt = ChatPromptTemplate.from_template(resume_summary_generation_prompt)\n",
    "resume_summary_generation_agent = resume_summary_generation_prompt | chat_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "jobDescription_summary_generation_prompt = \"\"\"\n",
    "Your task is to summarize in 1000 characters the provided job description in a concise format that \n",
    "can be easily compared with the summary of a resume.\n",
    "\n",
    "Provide your job description summary as follows:\n",
    "\n",
    "Output:::\n",
    "Job Description Summary: (your summarized version of the job description, structured for easy comparison with the summary of a resume)\n",
    "\n",
    "Now here is job description.\n",
    "\n",
    "job description: {jobDescription}\\n\n",
    "Output:::\"\"\"\n",
    "\n",
    "jobDescription_summary_generation_prompt = ChatPromptTemplate.from_template(jobDescription_summary_generation_prompt)\n",
    "jobDescription_summary_generation_agent = jobDescription_summary_generation_prompt | chat_model\n",
    "\n",
    "\n",
    "EVALUATION_PROMPT = \"\"\"###Task Description:\n",
    "An instruction (might include an Input inside it), a resume to evaluate, a job description that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
    "1. Write a detailed feedback that assess the quality of the resume strictly based on the given score rubric, not evaluating in general.\n",
    "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
    "3. The output format should look as follows: \\\"Feedback: {{write a feedback for criteria}} [RESULT] {{an integer number between 1 and 5}}\\\"\n",
    "4. Please do not generate any other opening, closing, and explanations. Be sure to include [RESULT] in your output.\n",
    "\n",
    "###The instruction to evaluate:\n",
    "A Persons resume for a Job.\n",
    "\n",
    "###Resume to evaluate:\n",
    "{resume}\n",
    "\n",
    "###Job Description (Score 5):\n",
    "{jobDescription}\n",
    "\n",
    "###Score Rubrics:\n",
    "[does the resume contain the Skills, Qualifications, and Experiences based on the Job Description?]\n",
    "Score 1: The resume contains completely no Skills, Qualifications, and Experiences.\n",
    "Score 2: The resume contains mostly no Skills, Qualifications, and Experiences.\n",
    "Score 3: The resume contains somwWhat Skills, Qualifications, and Experiences.\n",
    "Score 4: The resume contains mostly Skills, Qualifications, and Experiences.\n",
    "Score 5: The resume contains completely Skills, Qualifications, and Experiences.\n",
    "\n",
    "###Feedback:\"\"\"\n",
    "\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.schema import SystemMessage\n",
    "evaluation_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a fair evaluator language model.\"),\n",
    "        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_community.chat_models import ChatOpenAI\n",
    "eval_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa23d31-d298-482c-9c09-10ad86bf57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTextFromResume(file):\n",
    "    loader = PyPDFLoader(file)\n",
    "    pages = loader.load_and_split()\n",
    "    resume = \"\"\n",
    "    i = 0\n",
    "    for page in pages:\n",
    "        if i != 0:\n",
    "            resume += \"\\n\"\n",
    "        resume += page.page_content\n",
    "        i += 1\n",
    "    return resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2836f45e-7a0e-4147-84cd-a7b06367f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SummarizeResume(resume):\n",
    "    output = resume_summary_generation_agent.invoke({\"resume\": resume}).content\n",
    "    try:\n",
    "        summary = output.split(\"Summary:\")[2].split(\"Answer: \")[0]\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf4589f-7a42-4f04-9bdc-2e8e753669d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SummarizeJobDescription(jobDescription):\n",
    "    output = jobDescription_summary_generation_agent.invoke({\"jobDescription\":jobDescription}).content\n",
    "    try:\n",
    "        summary = output.split(\"Summary:\")[2].split(\"Answer: \")[0]\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        # return \"No summary of the resume....\"\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6c68e69-829f-4a52-906e-253476909278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(resumeSummary, jobDescriptionSummary):\n",
    "    eval_prompt_rag = evaluation_prompt_template.format_messages(\n",
    "        resume = resumeSummary,\n",
    "        jobDescription =jobDescriptionSummary,\n",
    "       )\n",
    "    eval_result = eval_chat_model.invoke(eval_prompt_rag)\n",
    "    try:\n",
    "        resume_feedback, resume_score = [item.strip() for item in eval_result.content.split(\"[RESULT]\")]\n",
    "        return [resume_feedback, resume_score]\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "305ace83-4780-49c5-9024-fc8502f2fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://9af5fc6393a1bec23b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9af5fc6393a1bec23b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(file, jobDescription):\n",
    "    \n",
    "    #Loads Text from resume\n",
    "    resume = loadTextFromResume(file)\n",
    "\n",
    "    #summarizes resume text for easy Job description comparison\n",
    "    resumeSummary = SummarizeResume(resume) \n",
    "\n",
    "    #Summarize Job description\n",
    "    jobDescriptionSummary = SummarizeJobDescription(jobDescription)\n",
    "\n",
    "    results = evaluate(resumeSummary, jobDescriptionSummary)\n",
    "    \n",
    "    res = f\"Match Score: {results[1]}\"\n",
    "    res += \"\\n\" + f\"feedback: {results[0]}\"\n",
    "    return res\n",
    "\n",
    "    \n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload Resume pdf only\"),\n",
    "        gr.Textbox(label=\"Job Description\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"JobFitScore\"\n",
    ")\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121eaf7b-11de-4dc7-b5a4-e94591e3095d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
